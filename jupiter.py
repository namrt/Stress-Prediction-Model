# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ekq3nilDkb3-zcK9DrG5f8DGNbyLKgF7
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler 
from sklearn import preprocessing
from sklearn import metrics




df=pd.read_csv('finaldata.csv')

#onehotencode
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
# Assigning numerical values and storing in another column

df['encWeekday'] = labelencoder.fit_transform(df['Weekday'])
df['encTimeOfDay'] = labelencoder.fit_transform(df['TimeOfDay'])
df['encsex'] = labelencoder.fit_transform(df['sex'])
scaleage = StandardScaler()
df['age'] = scaleage.fit_transform(np.array(df['age']).reshape(-1, 1))

#SMOTE
X = df[['age','encWeekday','encTimeOfDay', 'encsex']]
y = df['StressLevel']

from sklearn.model_selection import train_test_split 
  
# split into 70:30 ratio
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) 

from imblearn.over_sampling import SMOTE 
sm = SMOTE(random_state = 2) 
X_res, y_res = sm.fit_sample(X_train, y_train.ravel()) 
df = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res)], axis=1)
df.columns = ['age','encWeekday','encTimeOfDay', 'encsex','StressLevel']

#Modeling
from sklearn.model_selection import train_test_split 
X = df[['age','encWeekday','encTimeOfDay', 'encsex']]
y = df['StressLevel']
# split into 70:30 ration 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) 
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

'''
from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
#print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
'''

#tuning hyperParameters
''''# 5. Declare data preprocessing steps
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

 
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4]
# Method of selecting samples for training each tree
bootstrap = [True, False]

model_para = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
rf_model = RandomForestClassifier(random_state=1)

# set up grid search meta-estimator
clf = GridSearchCV(rf_model, model_params, cv=5)

# train the grid search meta-estimator to find the best model
model = clf.fit(X_train, y_train)

# print winning set of hyperparameters
from pprint import pprint
pprint(model.best_estimator_.get_params())
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test,y_pred))

'''
#tuned classifier

from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

 

model_params = {'n_estimators': [150],
               'max_features': ['sqrt'],
               'min_samples_split': [6],
               'min_samples_leaf': [1],
               'bootstrap': [True]}

rf_model = RandomForestClassifier(random_state=1)

# set up grid search meta-estimator
clf = GridSearchCV(rf_model, model_params, cv=5)

# train the grid search meta-estimator to find the best model
model = clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

#deploy
import pickle
pickle.dump(clf, open('model.pkl','wb'))

model = pickle.load(open('model.pkl','rb'))


#####################################

#trying new input

from datetime import date,datetime
import calendar

def gender(sex):
   if sex=='F':
      par=0
   else:
      par =1
   return par

def timeofday(x):
   if (x > 4) and (x <= 12 ):
        x ='Morning'
   elif (x > 12) and (x <= 16):
        x ='Noon'
   elif (x > 16) and (x <= 20) :
        x ='Eve'
   else:
        x ='Night'
   return x

def scale(value,max,min):
    newvalue= (max-min)/(max-min)*(value-max)+max
    return newvalue

param1 = int(input ("Enter Age :"))
sex = input ("Enter Sex (M/F):") 
param4=gender(sex)


my_date = date.today()
day=calendar.day_name[my_date.weekday()]
WD=day

now = datetime.now()
h=now.hour
TOD=timeofday(h)
#These values map to the hot one encoded values in the model
weekdayDict = {
  "Sunday": 3,
  "Monday": 1,
  "Tuesday": 5,
  "Wednesday": 6,
  "Thursday": 4,
  "Friday": 0,
  "Saturday": 2
}

#These values map to the hot one encoded values in the model
TimeOfDaydict={

  "Morning": 2,
  "Noon": 3,
  "Eve": 0,
  "Night": 2,
}

param3=TimeOfDaydict[TOD]
param2=weekdayDict[WD]

#preprocessing inputs
new_age = np.array([[param1]]) 
new_age_scaled = scaleage.transform(new_age)
new_data = np.array([[new_age_scaled ,param2,param3,param4]])    
new_data_scaled = scaler.transform(new_data)

print(model.predict(new_data_scaled))
